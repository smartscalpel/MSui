---
title: "SDA and Lasso classification of the MassPeaks data"
author: "Anatoly Sorokin"
date: '`r format(Sys.time(), "%d.%m.%Y")`'
output:
  pdf_document:
    keep_tex: yes
    number_sections: yes
  html_document: default
params:
  format: !r if(opts_knit$get("rmarkdown.pandoc.to") == 'html') c('screen', 'print')
    else 'print'
  version: !r if(nchar(Sys.which("git"))) system("git describe --long --dirty --abbrev=10  --tags  --always",
    intern=TRUE) else date()
header-includes:
- \usepackage[T2A]{fontenc}
- \usepackage[utf8]{inputenc}
- \usepackage[english,russian]{babel}
- \usepackage{grffile}
- \usepackage{rotating}
- \usepackage{caption}
- \usepackage{longtable}
- \usepackage{lscape}
---
```{r loadPackages, include=FALSE, cache=FALSE}
## load additional packages in this chunk
library(pander)
library(knitr)
library(scalpeldb)
library('Matrix')
library(ggplot2)
library(ggrepel)
library(data.table)
library(plyr)
library(xtable)
library(xcms)
library("FactoMineR")
library(cluster)
library(dendextend)
library(factoextra)
library(corrplot)
library(ncdf4)
library("PerformanceAnalytics")
library("pvclust")
library("sda")
library(RColorBrewer)
library(MALDIquant)
library(MALDIquantForeign)
library(glmnet)
library(analyzePeaks)
library(crossval)
library(pROC)
library(ForecastCombinations)
library(Vennerable)
library(openxlsx)
ticThreshold<-0.01
absTicThreshold<-1000
Npeaks<-10
filterTrain<-FALSE
logFile<-'/Users/lptolik/Documents/Projects/MSui/SDAmodelReport.log'
```

```{r setup, include=FALSE, cache=FALSE}
## This chunk should contain global configuration commands.
## Use this to set knitr options and related things. Everything
## in this chunk will be included in an appendix to document the
## configuration used.
#output <- opts_knit$get("rmarkdown.pandoc.to")
opts_knit$set(stop_on_error = 2L)

## By default R code is only included in HTML versions of the report
## (where it can be collapsed). You can generate a PDF version
## using rmarkdown::pdf_document to get a copy for print. Extensive
## chunks of R code may or may not be desired in /hat setting. If you
## want them simply change the following arguments to `echo = TRUE`.
## In either case the default can be overwritten for individual chunks.
#opts_chunk$set(echo = output=="html")
#opts_chunk$set(warning = output=="html")
#opts_chunk$set(message = output=="html")

## Cache options
opts_chunk$set(cache=TRUE)

## Figure options
## Set default figure format
#options(reportmd.figure.format=params$format)

## Set 'hide.fig.code' to FALSE to include code chunks that
## produce Figures in the output. Note that this affects all chunks
## that provide a figure caption.
opts_chunk$set(hold=TRUE, hide.fig.code=FALSE)

## Set up default plotting options for different formats.
## These can be overwritten for individual chunks
#interactiveFig()
#screenFig()
#printFig()

## Pander options
panderOptions("digits", 3)
panderOptions("table.split.table", 160)
#panderOptions("table.style", "grid")

## Configure Figure and Table lables
#options(figcap.prefix = "Figure", figcap.sep = ":", figcap.prefix.highlight = "**")
#options(tabcap.prefix = "Table", tabcap.sep = ":", tabcap.prefix.highlight = "**")

## Install required knitr hooks
#installHooks()
```

```{r functions, include=FALSE}
## Custom functions used in the analysis should go into this chunk.
## They will be listed in their own section of the appendix.
rowMax<-function(x){
  return(apply(x,1,max))
}
##==================== CAT score ====================##
getCorrStruct<-function(X,cutoff=0.85){
  cm<-cor(X)
  h<-hclust(as.dist(1-abs(cm)),method = 'ward.D2')
  c<-cutree(h,h=1)
  ncl<-max(c);ncl
  mmm<-min(sapply(1:ncl,function(k){j<-which(c==k);return(min(min(abs(cm[j,j]))))}))
  while(mmm<cutoff){
    ccl<-ncl+1
    c<-cutree(h,k=ccl)
    ncl<-max(c);ncl
    mmm<-min(sapply(1:ncl,function(k){j<-which(c==k);return(min(min(abs(cm[j,j]))))}))
  }
  return(c)
}

groupCATscore<-function(X,class,cutoff=0.85){
  tstat = catscore(as.matrix(X), class)
  c<-getCorrStruct(X,cutoff)
  laply(c,function(jj){j<-which(c==jj);tmp<-sign(tstat[j,])*sqrt(sum(tstat[j,]^2));tmp[j==j[1]]})->tmp
colnames(tmp)<-paste0('g',colnames(tmp))
res<-cbind(as.data.frame(tstat[TRUE,]),tmp)
return(res[order(abs(tmp[,1]),decreasing = TRUE),])

}

##==================== Functions ====================##
data(isotopes)

lasso.res<-list()
lda.res<-list()
dda.res<-list()
print_table<-function(mat){
  addtorow          <- list()
  addtorow$pos      <- list()
  addtorow$pos[[1]] <- c(0)
  addtorow$command  <- c(
    paste(
      "\\hline \n",
      "\\endhead \n",
      "\\hline \n",
      "\\multicolumn{3}{l}{\\footnotesize Continued on next page} \n",
      "\\endfoot \n",
      "\\endlastfoot \n",sep = ""
    )
  )
  cat(
    sprintf(
      "\\begin{center}\n\\captionof{table}{Wide ranges of continious peaks (width>%d)}\n\\scriptsize",50
    )
  )
  print(
    xtable(
      mat)
    ,size = "small",include.colnames = TRUE,
    tabular.environment = "longtable",
    floating = FALSE,include.rownames = TRUE,
    add.to.row = addtorow,
    hline.after =c(-1)
  )
  cat("\\end{center}\n ")
}
roundScan<-function(i){
  scan <- as.data.table(getScan(xraw, sel$scanidx[i], sel$mzrange))
  sc1<-scan[,.(intensity=median(intensity)),by=.(mz=round(mz,0))]
  m<-matrix(rep(0,2000),nrow = 1)
  m[1,sc1[mz<=200]$mz]<-sc1[mz<=200]$intensity
  return(m)
}

parseScan<-function(i){
scan <- as.data.table(getScan(xraw, sel$scanidx[i], sel$mzrange))
p<-data.frame(id=as.integer(-1),
mz=scan$mz,
mz1=round(scan$mz,0),
mz100=round(scan$mz,2),
rt=xraw@scantime[i],
scan=i,
intensity=scan$intensity,
spectrid=as.integer(-1),
reltic=-1e-6)
tot<-sum(p$intensity)
p$reltic<-p$intensity/tot
return(p)
}

predfun.dda <- function(Xtrain, Ytrain, Xtest, Ytest,negative) {
dda.fit <- sda(Xtrain, Ytrain, diagonal=TRUE, verbose=FALSE)
dda.res[[length(dda.res)+1]]<<-dda.fit
  ynew <- predict(dda.fit, Xtest, verbose=FALSE)$class
return(confusionMatrix(Ytest, ynew, negative=negative)) }

predfun.lda <- function(Xtrain, Ytrain, Xtest, Ytest,negative) {
lda.fit <- sda(Xtrain, Ytrain, diagonal=FALSE, verbose=FALSE)
lda.res[[length(lda.res)+1]]<<-lda.fit
  ynew <- predict(lda.fit, Xtest, verbose=FALSE)$class
return(confusionMatrix(Ytest, ynew, negative=negative)) }

predfun.lasso <- function(Xtrain, Ytrain, Xtest, Ytest,negative,labels) {
lasso.fit <- cv.glmnet(Xtrain, Ytrain, family='binomial', 
                       alpha=1, parallel=TRUE, 
                       standardize=TRUE, 
                       type.measure='auc')
lasso.res[[length(lasso.res)+1]]<<-lasso.fit
lambda <- lasso.fit$lambda.min
  ynew <- round(predict(lasso.fit, Xtest, 
                        type = "response",
                        s="lambda.min")+1,0)
  if(length(unique(ynew))<length(labels)){
  res<-factor(
    ynew,
    labels = labels[unique(ynew)])
  }else{
  res<-factor(
    ynew,
    labels = labels)
  }
return(confusionMatrix(Ytest, res, negative=negative)) }


########################
## FUNCTIONS ADOPTED FROM MALDIQUANT
#######################

## .unlist
##  wrapper for unlist
##
## params:
##  x: an R object
##
## returns:
##  see also ?unlist
##
.unlist <- function(x) {
  unlist(x, recursive=FALSE, use.names=FALSE)
}

#' .colCors
#'
#' Calculate the correlation for two matrices columnwise.
#'
#' @param x matrix/data.frame
#' @return double
#' @author Sebastian Gibb <mail@@sebastiangibb.de>
#' @noRd
.colCors <- function(x, y, na.rm=FALSE) {
  stopifnot(is.matrix(x) && is.matrix(y))
  stopifnot(all(dim(x) == dim(y)))

  if (na.rm) {
    isNA <- is.na(x) | is.na(y)
    x[isNA] <- NA_real_
    y[isNA] <- NA_real_
  }

  cmX <- colMeans(x, na.rm=na.rm)
  cmY <- colMeans(y, na.rm=na.rm)

  (colMeans(x * y, na.rm=na.rm) - (cmX * cmY)) /
    (sqrt(colMeans(x * x, na.rm=na.rm) - cmX * cmX) *
     sqrt(colMeans(y * y, na.rm=na.rm) - cmY * cmY))
}

#' .pseudoCluster
#'
#' Find possible isotopic cluster in mass/mz data.
#'
#' @param x double, mass
#' @param size integer, cluster size, number of peaks per cluster
#' @param distance double, distance between isotopes (mass of a neutron; see
#' Park et al 2008); could be of length > 1 (if > 1: order will affect later
#' removal in .monoisotopicPattern).
#' @param tolerance double, mass tolerance
#' @return a matrix of indices (nrow(x) == n) of potential clusters
#' @references
#' K. Park, J.Y. Yoon, S. Lee, E. Paek, H. Park, H.J. Jung, and S.W. Lee. 2008.
#' Isotopic peak intensity ratio based algorithm for determination of isotopic
#' clusters and monoisotopic masses of polypeptides from high-resolution
#' mass spectrometric data.
#' Analytical Chemistry, 80: 7294-7303.
#' @noRd
.pseudoCluster <- function(x, size=3L, distance=1.00235, tolerance=1e-4) {
  if (size < 2L) {
    stop("The ", sQuote("size"), " of a cluster has to be at least 2!")
  }
  mm <- matrix(x, nrow=size, ncol=length(x) * length(distance), byrow=TRUE)
  ms <- mm + (rep(distance, each=size) * 0L:(size - 1L))

  i <- match.closest(ms, x, tolerance=mm * tolerance)
  dim(i) <- dim(ms)

  i[, !is.na(colSums(i)), drop=FALSE]
}

#' .F
#'
#' Map mass to poisson mean/lambda.
#'
#' @param mass double, mass from experimental peak list
#' @return double suitable to pass to `dpois`
#' @references
#' E.J. Breen, F.G. Hopwood, K.L. Williams, and M.R. Wilkins. 2000.
#' Automatic poisson peak harvesting for high throughput protein identification.
#' Electrophoresis 21 (2000): 2243-2251.
#' @noRd
.F <- function(x)0.000594 * x + 0.03091

#' .P
#'
#' Model isotopic distribution by poisson distribution.
#'
#' @param mass double, mass from experimental peak list
#' @param isotopes integer, which isotopes
#' @return double, isotopic distribution
#' @references
#' E.J. Breen, F.G. Hopwood, K.L. Williams, and M.R. Wilkins. 2000.
#' Automatic poisson peak harvesting for high throughput protein identification.
#' Electrophoresis 21 (2000): 2243-2251.
#' @noRd
.P <- function(x, isotopes)dpois(isotopes, .F(x))

#' .Psum
#'
#' Model isotopic distribution by poisson distribution and sum to 1 (similar to
#' TIC).
#'
#' @param mass double, mass from experimental peak list
#' @param isotopes integer, which isotopes
#' @return double, isotopic distribution
#' @references
#' E.J. Breen, F.G. Hopwood, K.L. Williams, and M.R. Wilkins. 2000.
#' Automatic poisson peak harvesting for high throughput protein identification.
#' Electrophoresis 21 (2000): 2243-2251.
#' @noRd
.Psum <- function(x, isotopes) {
  ni <- length(isotopes)
  nx <- length(x)
  p <- .P(rep.int(x, rep.int(ni, nx)), isotopes)
  dim(p) <- c(ni, nx)
  t(t(p) / colSums(p))
}

#' .monoisotopicPattern
#'
#' Model isotopic distribution by poisson distribution.
#'
#' @param x double, mass from experimental peak list
#' @param y double, intensity from experimental peak list
#' @param tolerance double, mass tolerance for .pseudoCluster
#' @param minCor double, minimal correlation between experimental and model
#' intensities
#' @param distance double, distance between isotopes (mass of a neutron; see
#' Park et al 2008); could be of length > 1; if length > 1 the order matters.
#' The first distance elements are prefered (the last elements are possible
#' removed because the contain duplicated indices).
#' @param size integer, cluster size (number of peaks for a possible cluster),
#' see .pseudoCluster
#' @return matrix, index of monoisotopic masses in first row
#' @references
#' E.J. Breen, F.G. Hopwood, K.L. Williams, and M.R. Wilkins. 2000.
#' Automatic poisson peak harvesting for high throughput protein identification.
#' Electrophoresis 21 (2000): 2243-2251.
#' @noRd
.monoisotopicPattern <- function(x, y, minCor=0.95, tolerance=1e-4,
                                 distance=1.00235, size=3L) {
  pc <- .pseudoCluster(x, size=size, distance=distance, tolerance=tolerance)
  y <- y[pc]
  dim(y) <- dim(pc)
  y <- t(t(y)/colSums(y))
  p <- .Psum(x[pc[1L,]], isotopes=0L:(size-1L))
  cr <- .colCors(y, p)
  pc <- pc[, cr > minCor, drop=FALSE]
  pc[duplicated(as.vector(pc))] <- NA_real_
  pc[, !is.na(colSums(pc)), drop=FALSE]
}

#' .monoisotopic
#'
#' Loop through multiple .monoisotopicPattern outputs and remove duplicated
#' peaks.
#'
#' @param x double, mass from experimental peak list
#' @param y double, intensity from experimental peak list
#' @param size integer vector, cluster size
#' @param \ldots further arguments passed to .monoisotopicPattern
#' @return double, index of monoisotopic masses
#' @noRd
.monoisotopic <- function(x, y, size=3L:10L, ...) {
  if (length(x) && length(x) == length(y)) {
    pattern <- lapply(sort.int(size, decreasing=TRUE),
                      function(s).monoisotopicPattern(x=x, y=y, size=s, ...))
    upattern <- .unlist(pattern)
    upattern[duplicated(upattern)] <- NA_real_
    upattern <- relist(upattern, pattern)
    sort.int(.unlist(lapply(upattern,
                            function(p)p[1L, !is.na(colSums(p))])))
  } else {
    double()
  }
}

#' .isotopic
#'
#' Loop through multiple .monoisotopicPattern outputs, remove duplicated
#' peaks, and return isotopic series.
#'
#' @param x double, mass from experimental peak list
#' @param y double, intensity from experimental peak list
#' @param size integer vector, cluster size
#' @param \ldots further arguments passed to .monoisotopicPattern
#' @return double, index of monoisotopic masses
#' @noRd
.isotopic <- function(x, y, size=3L:10L, ...) {
  if (length(x) && length(x) == length(y)) {
    pattern <- lapply(sort.int(size, decreasing=TRUE),
                      function(s).monoisotopicPattern(x=x, y=y, size=s, ...))
    upattern <- .unlist(pattern)
    upattern[duplicated(upattern)] <- NA_real_
    upattern <- relist(upattern, pattern)
    sort.int(.unlist(lapply(upattern,
                            function(p)p[-1L, !is.na(colSums(p))])))
  } else {
    double()
  }
}

.myPeaks<-function(p, minCor=0.95, tolerance=1e-4, size=2L:10L) {
  niI<-.isotopic(x=MALDIquant::mass(p), y=MALDIquant::intensity(p),
                 minCor=0.95, tolerance=1e-4,
                 distance=1.00235, size=2L:7L)
  iP<-p[-niI]
  niICl<-.isotopic(x=MALDIquant::mass(iP), y=MALDIquant::intensity(iP),
                   minCor=0.95, tolerance=1e-4,
                   distance=1.99705, size=2L:7L)
  iPCl<-iP[-niICl]
  return(iPCl)
}

.myPeakList<-function(object, minCor=0.95, tolerance=1e-4, size=2L:10L) {
  lapply(object,.myPeaks,minCor=minCor, tolerance=tolerance, size=size)
}


.mPeaks<-function(object, minCor=0.95, tolerance=1e-4,
                              distance=1.00235, size=3L:10L) {
object[.monoisotopic(x=MALDIquant::mass(object), y=MALDIquant::intensity(object),
                       minCor=minCor, tolerance=tolerance,
                       distance=distance, size=size)]
}

.mPeakList<-function(object, minCor=0.95, tolerance=1e-4,
                              distance=1.00235, size=3L:10L) {
  lapply(object,.mPeaks,minCor=minCor, tolerance=tolerance,
                       distance=distance, size=size)
}

### mycrossval.R  (2014-03-29)
###
###    Generic Function for Cross Valdidation 
###
### Copyright 2009-14  Korbinian Strimmer
###
###
### This file is part of the `mycrossval' library for R and related languages.
### It is made available under the terms of the GNU General Public
### License, version 3, or at your option, any later version,
### incorporated herein by reference.
### 
### This program is distributed in the hope that it will be
### useful, but WITHOUT ANY WARRANTY; without even the implied
### warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR
### PURPOSE.  See the GNU General Public License for more
### details.
### 
### You should have received a copy of the GNU General Public
### License along with this program; if not, write to the Free
### Software Foundation, Inc., 59 Temple Place - Suite 330, Boston,
### MA 02111-1307, USA



# general routines for conducting cross validation


#  predfun(Xtrain, Ytrain, Xtest, Ytest, ...)
#  must be given

# B times repeated K-fold cross-validation 
mycrossval = function(predfun,
                       X, Y, 
                       smpl, # data frame with two colums: ff the file of the spectra and diag for diagnosis
                       ff, # mappings of X to smpl$ff
                       K=6,  # number of folds
                       B=20,  # number of repetitions
                       verbose=TRUE,
                       ...    # optional arguments for predfun
)
{
  ygrouped = group.samples(as.factor(smpl$diag))
 
  # makes no sense to have more folds than entries in largest group
  groupsize = sapply(ygrouped, length)
  nfolds = min(K, max(groupsize))
  if (verbose) cat("Number of folds:", nfolds, "\n")


  allfolds = B*nfolds
  if (verbose) cat("Total number of CV fits:", allfolds, "\n")
 
  stat.cv = NULL
 
  i = 1
  for (b in 1:B)
  {
    if (verbose) cat("\nRound #", b, "of", B, "\n")

    folds = get.folds(ygrouped, K=nfolds)

    for (f in 1:nfolds)
    {
      if (verbose) cat("CV Fit #", i, "of", allfolds, "\n")

      #### prepare  test and training data set ####

      test.idx = which(ff%in%smpl$ff[folds[[f]]])
      train.x = X[-test.idx, , drop=FALSE]                     
      train.y = Y[-test.idx]
      test.x = X[test.idx, , drop=FALSE] 
      test.y = Y[test.idx]

      ### learn predictor and compute test error ####
      stat.new = predfun(train.x, train.y, test.x, test.y, ...)
      stat.cv = rbind(stat.cv, stat.new)

      rownames(stat.cv)[i] = paste0("B",b,".F",f)

      i = i+1
    }   
  }

  stat = apply(stat.cv, 2, mean)
  stat.se = apply(stat.cv, 2, sd) / sqrt(allfolds)

  return(list(stat.cv=stat.cv, stat=stat, stat.se=stat.se))
}


########################################################################
# private functions
########################################################################

# return a list with samples arranged by group
group.samples = function(y)
{
  # split samples into groups
  if(is.factor(y))
  {
    ygrouped = split(seq(y), y)
  }
  else
  {
    ygrouped = list(all=seq(length(y)))
  }

  return( ygrouped )
}

# divide samples into sets of similar size with 
# evenly distributed samples (balanced per group) 
get.folds = function(ygrouped, K)
{
  # makes no sense to have more folds than entries in largest group
  groupsize = sapply(ygrouped, length)
  nfolds = min(K, max(groupsize))
  if (K != nfolds) cat("Number of folds:", nfolds, "\n")
  
  # assign the members of each group evenly to the folds
  m = NULL
  for (i in 1:length(ygrouped) )
  {
     a = ceiling(groupsize[i]/nfolds)
     ridx = sample.int(groupsize[i], groupsize[i])
     v = c( rep(NA, nfolds*a-groupsize[i]), ygrouped[[i]][ridx] ) # pad with NAs
     ridx = sample.int(nfolds, nfolds) # reshuffle column containing the NAs
     v[1:nfolds] = v[ridx]
     m = c(m,v)
  }
  m = matrix(m, nrow=nfolds) # note that all NAs of a group are all in one column

  folds =  vector("list", nfolds)
  for(j in 1:nfolds)
  {
    keep = !is.na(m[j , ])
    folds[[j]] = m[j, keep]
  }

  return( folds )
}

# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
# The code is taken from 
# http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

getMD<-function(p){
  as.data.frame(metaData(p))
}

getRMSD<-function(pred,obs){
  round(sqrt(mean((pred - (as.numeric(obs)-1))^2)), 3)
}

aggregatePredictions<-function(idx,matr,annot,fun=median){
  apply(matr[annot==idx,],1,fun)
}
```

```{r echo=FALSE, include=FALSE}
pathDef<-'~/Dropbox/Скальпель/DBData/peaks/'
flDef<-c("peak2019.diag_32.expt_1.res_1.mode_2.dev_2.mz_2.tsv.gz",
        "peak2019.diag_6.expt_1.res_1.mode_2.dev_2.mz_2.tsv.gz" )
modelDef<-'~/Dropbox/Скальпель/DBData/SDAreports2020/SDAreport.diag_6.res_1.mode_2.mz_2/SDAfilesReport.models.RData'
```

# Read data
Before running the code a number of variables should be setted for appropriate data loading:
 
 3. the path to folder with data files *peak.path*
 4. names of files to build dataset from *fl*
 


```{r check.values}
if(!(exists('fl')&
     exists('peak.path')&
     exists('modelPath'))){
  warning('not all obligatory parameters are provided\nUsing defaults.\n')
  cat(format(Sys.time(), "%b %d %X"),'not all obligatory parameters are provided\nUsing defaults.\n',file = logFile,append = TRUE)
  fl<-flDef
  peak.path<-pathDef
  modelPath<-modelDef
  wdir<-getwd()
  cacheDef<-TRUE
}else{
  cacheDef<-TRUE #FALSE
}
#lipids<-read.csv('DetectedLipids.csv')
#lipids<-lipids[order(lipids$PEAK),]
lfl<-strsplit(x = fl,split = '\\.')
dfl<-unique(ldply(lfl,.fun = function(l1)
  data.frame(diag=sub('diag_', '',l1[2]),
             res=sub('res_', '',l1[4]),
             mode=sub('mode_', '',l1[5]),
             mz=sub('mz_', '',l1[7]))))
idx<-which(dfl$diag!=32)
if(length(idx)!=1){
  stop('there is more than one experimental setup in the datafiles\n')
}
dname<-paste0('diag_',dfl$diag[idx],
              '.res_',dfl$res[idx],
              '.mode_',dfl$mode[idx],
              '.mz_',dfl$mz[idx])
load(modelPath)
if(filterTrain){
  trainPath<-sub('SDAfilesReport.models.RData','SDAfilesReport.fm.Rdata',modelPath)
  load(trainPath)
}
cat(format(Sys.time(), "%b %d %X"),dname,"'",wdir,"','",peak.path,"'",'\n\t',
    fl,'\n',file = logFile,append = TRUE)
```

```{r fl}
fl
```

```{r peak.path}
peak.path
```

```{r makePeakList,cache=cacheDef}
peaks<-getPeakList(fl,peak.path)
dl<-lapply(peaks, getMD)
md<-do.call(rbind,dl)

```

# Подготовка данных к анализу


```{r datasetname.raw.metadata.dataSet}
diag<-unlist(sapply(peaks,function(.x)metaData(.x)$diag))
spectrumid<-unlist(sapply(peaks,function(.x)metaData(.x)$spectrumid))
qplot(as.character(diag),log='y')
pander(table(diag))
ln<-sapply(peaks,length)
qplot(ln,bins=100,log = 'x')
idx<-which(ln>Npeaks)
lpeaks<-peaks[idx]
ppeaks<-lpeaks
md<-md[idx,]
diag<-diag[idx]
l<-unique(md$diagnosis)
cls<-factor(md$diagnosis,levels=c(32,l[l!=32]),ordered=TRUE)
ff<-factor(spectrumid)
```


```{r datasetname.make.fm,cache=TRUE}
minNum<-0.25*length(which(md$diagnosis==32))
predict.fm<-analyzePeaks::getPeaks(lpeaks,
                                   dda.res.full[[1]],
                                   tolerance=2e-4,
                                   minNumber = minNum)
predict.tot<-predict.fm
md.tot<-md
if(filterTrain){
  idx.train<-which(is.na(match(md$scan,mdf$scan)))
  if(length(unique(cls[-idx.train]))<2){
    cat('\n\n############\n',
        '   **There is only one class in validation dataset**\n',
        '   Further analysis performed with whole dataset\n',
        '############\n\n')
    filterTrain<- FALSE
  }else if(length(unique(cls[idx.train]))<2){
    cat('\n\n############\n',
        '   **There is only one class in training dataset**\n',
        '   Further analysis performed with whole dataset\n',
        '############\n\n')
    filterTrain<- FALSE
  }
}
if(filterTrain){
  train.fm<-predict.fm[-idx.train,]
  predict.fm<-predict.fm[idx.train,]
  train.md<-md[-idx.train,]
  md<-md[idx.train,]
  train.cls<-cls[-idx.train]
  cls<-cls[idx.train]
  ppeaks<-lpeaks[idx.train]
}else{
  train.fm<-predict.fm
  train.md<-md
  train.cls<-cls
}
train.best<-list()
test.best<-list()
```
```{r base.stat.plots}
qplot(as.character(cls),log='y')
pander(table(cls))
ln<-sapply(ppeaks,length)
qplot(ln,bins=100,log = 'x')

```


```{r datasetname.raw.spectra.facet,fig.width=8.5,fig.height=8.5,dev='png'}
cat(format(Sys.time(), "%b %d %X"),dname,'Feature matrces are ready\n',file = logFile,append = TRUE)
mz<-as.double(colnames(predict.fm))
md$diag<-cls
df<-cbind(md,as.data.frame(predict.fm))
pldf<-melt(df,id=names(md))
pldf$mz<-round(as.numeric(as.character(pldf$variable)),4)

labIdx<-order(pldf$value,decreasing = TRUE)[1:10]
#ggplot(pldf)+geom_segment(aes(x=mz,xend=mz,y=0,yend=value,color=diag,alpha=0.5))+
#  labs(title ='Combined plot')

ggplot(pldf)+geom_segment(aes(x=mz,xend=mz,y=0,yend=value))+
  facet_grid(diag~.)+ 
  labs(title ='Intensity')
```


```{r datasetname.raw.spectra.sc.facet.sum,fig.width=8.5,fig.height=8.5,dev='png'}
sfm<-t(scale(t(predict.fm),scale = rowSums(predict.fm)/1e6,center = FALSE))
sdf<-cbind(md,as.data.frame(sfm))
spldf<-melt(sdf,id=names(md))
spldf$mz<-round(as.numeric(as.character(spldf$variable)),4)

# pldf<-data.frame(mz=c(mz,mz),
#                  intensity=c(high,low),
#                  type=c(rep('high',length(mz)),rep('low',length(mz))),
#                  scint=c(high/max(high),low/max(low)))
labIdx<-order(spldf$value,decreasing = TRUE)[1:10]
#ggplot(spldf)+geom_segment(aes(x=mz,xend=mz,y=0,yend=value,color=diag,alpha=0.5))+
#  labs(title ='Combined plot')
ggplot(spldf)+geom_segment(aes(x=mz,xend=mz,y=0,yend=value))+
  facet_grid(diag~.,scales = "free_y") +
  xlim(400, 1000) + 
  labs(title ='Intensity')
```


```{r datasetname.raw.spectra.sc.facet.max,fig.width=8.5,fig.height=8.5,dev='png'}
sfm<-t(scale(t(predict.fm),scale = rowMax(predict.fm)/1e6,center = FALSE))
sdf<-cbind(md,as.data.frame(sfm))
spldf<-melt(sdf,id=names(md))
spldf$mz<-round(as.numeric(as.character(spldf$variable)),4)

# pldf<-data.frame(mz=c(mz,mz),
#                  intensity=c(high,low),
#                  type=c(rep('high',length(mz)),rep('low',length(mz))),
#                  scint=c(high/max(high),low/max(low)))
labIdx<-order(spldf$value,decreasing = TRUE)[1:10]
#ggplot(spldf)+geom_segment(aes(x=mz,xend=mz,y=0,yend=value,color=diag,alpha=0.5))+
#  labs(title ='Combined plot')
ggplot(spldf)+geom_segment(aes(x=mz,xend=mz,y=0,yend=value))+
  facet_grid(diag~.) +
  xlim(400, 1000) + 
  labs(title ='Intensity')
```


## PCA

### Non-scaled data

```{r datasetname.raw.pca.nosc.full,fig.width=8.5,fig.height=8.5}
cat(format(Sys.time(), "%b %d %X"),dname,'PCA starts\n',file = logFile,append = TRUE)
pca<-try(prcomp(predict.fm,scale. = FALSE),silent=TRUE)
if(class(pca)!="try-error"){
  fviz_screeplot(pca, ncp=15)
  fviz_pca_ind(pca, habillage='none',label = 'none',
               addEllipses=FALSE)
  fviz_pca_ind(pca, habillage='none',label = 'none',axes=c(1,3),
               addEllipses=FALSE)
  fviz_pca_ind(pca, habillage=cls,
               addEllipses=TRUE, ellipse.level=0.95)
  fviz_pca_ind(pca, habillage=cls,axes=c(1,3),
               addEllipses=TRUE, ellipse.level=0.95)
}else{
  cat('Non-scaled data did not converge\n')
}
```

### Scaled data

```{r datasetname.raw.pca.sc.full,fig.width=8.5,fig.height=8.5}
pca<-prcomp(predict.fm[,which(apply(predict.fm,2,sd)>0)],scale. = TRUE)
fviz_screeplot(pca, ncp=15)
fviz_pca_ind(pca, habillage='none',label = 'none',
             addEllipses=FALSE)
fviz_pca_ind(pca, habillage='none',label = 'none',axes=c(1,3),
             addEllipses=FALSE)
fviz_pca_ind(pca, habillage=cls,
             addEllipses=TRUE, ellipse.level=0.95)
fviz_pca_ind(pca, habillage=cls,axes=c(1,3),
             addEllipses=TRUE, ellipse.level=0.95)
```


# Diagonal Discriminative Analysis

## Full dataset
```{r dda.full.get.train,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(dda.res.full[[1]])
labM.dda.full<-matrix(train.md$diagnosis,nrow = length(train.md$diagnosis),ncol = length(dda.res.full))
trainL.dda.full<-lapply(dda.res.full,
                   function(.m)analyzePeaks::getPrediction(train.fm,.m))
terrL.dda.full<-lapply(trainL.dda.full,
                   function(.x)diagnosticErrors(
                     confusionMatrix(train.md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
terrM.dda.full<-as.data.frame(do.call(rbind,terrL.dda.full))
train.probL.dda.full<-lapply(trainL.dda.full,function(.x).x$probII)
train.probM.dda.full<-do.call(cbind,train.probL.dda.full)
train.auc<- caTools::colAUC(train.probM.dda.full,train.cls,plotROC = TRUE)
terrM.dda.full$AUC<-t(train.auc)
terrM.dda.full<-cbind(
  data.frame(mIdx=1:length(dda.res.full),
             type='DDA',
             nFeatures=length(mz)),
  terrM.dda.full)
```

```{r dda.full.get.predictions,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(dda.res.full[[1]])
labM.dda.full<-matrix(md$diagnosis,nrow = length(md$diagnosis),ncol = length(dda.res.full))
predL.dda.full<-lapply(dda.res.full,
                   function(.m)analyzePeaks::getPrediction(predict.fm,.m))
derrL.dda.full<-lapply(predL.dda.full,
                   function(.x)diagnosticErrors(
                     confusionMatrix(md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
derrM.dda.full<-as.data.frame(do.call(rbind,derrL.dda.full))
probL.dda.full<-lapply(predL.dda.full,function(.x).x$probII)
probM.dda.full<-do.call(cbind,probL.dda.full)
auc<- caTools::colAUC(probM.dda.full,cls,plotROC = TRUE)
derrM.dda.full$AUC<-t(auc)
derrM.dda.full<-cbind(
  data.frame(mIdx=1:length(dda.res.full),
             type='DDA',
             nFeatures=length(mz)),
  derrM.dda.full)
```

```{r dda.full.plots}
p1<-qplot(acc,AUC,data = derrM.dda.full)
p2<-qplot(sens,AUC,data = derrM.dda.full)
p3<-qplot(spec,AUC,data = derrM.dda.full)
p4<-qplot(sens,spec,data = derrM.dda.full)

multiplot(p1,p2,p3,p4,cols = 2)
```

```{r dda.full.table}
ridx<-unique(c(
  which.max(derrM.dda.full$acc),
  which.max(derrM.dda.full$sens),
  which.max(derrM.dda.full$spec),
  which.max(derrM.dda.full$AUC)))
pander(derrM.dda.full[ridx,])
```

```{r dda.full.analyse.best.model.train}
idxBest<-which.max(terrM.dda.full$AUC)
dda.full.best<-dda.res.full[[idxBest]]
t<-trainL.dda.full[[idxBest]]
train.best[['dda.full']]<-t$probII
t$diag<-as.character(train.cls)
dda.full.roc.train<-roc(t$diag,t$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bct<-coords(dda.full.roc.train,"best",
            best.method='c',
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bct)<-'training'
```

```{r dda.full.analyse.best.model.test}
p<-predL.dda.full[[idxBest]]
p$diag<-as.character(cls)
test.best[['dda.full']]<-p$probII
dda.full.roc.pred<-roc(p$diag,p$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bcp<-coords(dda.full.roc.pred,x=bct$threshold,
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bcp)<-'validation'
dda.full.best.threshold<-as.data.frame(t(rbind(bct,bcp)))
pander(dda.full.best.threshold)
```

## Top 20

```{r dda.top20.get.train,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(dda.res.top20[[1]])
labM.dda.top20<-matrix(train.md$diagnosis,nrow = length(train.md$diagnosis),ncol = length(dda.res.top20))
trainL.dda.top20<-lapply(dda.res.top20,
                   function(.m)analyzePeaks::getPrediction(train.fm,.m))
terrL.dda.top20<-lapply(trainL.dda.top20,
                   function(.x)diagnosticErrors(
                     confusionMatrix(train.md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
terrM.dda.top20<-as.data.frame(do.call(rbind,terrL.dda.top20))
train.probL.dda.top20<-lapply(trainL.dda.top20,function(.x).x$probII)
train.probM.dda.top20<-do.call(cbind,train.probL.dda.top20)
train.auc<- caTools::colAUC(train.probM.dda.top20,train.cls,plotROC = TRUE)
terrM.dda.top20$AUC<-t(train.auc)
terrM.dda.top20<-cbind(
  data.frame(mIdx=1:length(dda.res.top20),
             type='DDA',
             nFeatures=length(mz)),
  terrM.dda.top20)
```

```{r dda.top20.get.predictions,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(dda.res.top20[[1]])
labM.dda.top20<-matrix(md$diagnosis,nrow = length(md$diagnosis),ncol = length(dda.res.top20))
predL.dda.top20<-lapply(dda.res.top20,
                   function(.m)analyzePeaks::getPrediction(predict.fm,.m))
derrL.dda.top20<-lapply(predL.dda.top20,
                   function(.x)diagnosticErrors(
                     confusionMatrix(md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
derrM.dda.top20<-as.data.frame(do.call(rbind,derrL.dda.top20))
probL.dda.top20<-lapply(predL.dda.top20,function(.x).x$probII)
probM.dda.top20<-do.call(cbind,probL.dda.top20)
auc<- caTools::colAUC(probM.dda.top20,cls,plotROC = TRUE)
derrM.dda.top20$AUC<-t(auc)
derrM.dda.top20<-cbind(    data.frame(mIdx=1:length(dda.res.top20),
             type='DDA',
             nFeatures=length(mz)),
derrM.dda.top20)
```

```{r dda.top20.plots}
p1<-qplot(acc,AUC,data = derrM.dda.top20)
p2<-qplot(sens,AUC,data = derrM.dda.top20)
p3<-qplot(spec,AUC,data = derrM.dda.top20)
p4<-qplot(sens,spec,data = derrM.dda.top20)

multiplot(p1,p2,p3,p4,cols = 2)
```

```{r dda.top20.table}
ridx<-unique(c(
  which.max(derrM.dda.top20$acc),
  which.max(derrM.dda.top20$sens),
  which.max(derrM.dda.top20$spec),
  which.max(derrM.dda.top20$AUC)))
pander(derrM.dda.top20[ridx,])
```

```{r dda.top20.analyse.best.model.train}
idxBest<-which.max(terrM.dda.top20$AUC)
dda.top20.best<-dda.res.top20[[idxBest]]
t<-trainL.dda.top20[[idxBest]]
t$diag<-as.character(train.cls)
train.best[['dda.top20']]<-t$probII
dda.top20.roc.train<-roc(t$diag,t$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bct<-coords(dda.top20.roc.train,"best",
            best.method='c',
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bct)<-'training'
```

```{r dda.top20.analyse.best.model.test}
p<-predL.dda.top20[[idxBest]]
p$diag<-as.character(cls)
test.best[['dda.top20']]<-p$probII
dda.top20.roc.pred<-roc(p$diag,p$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bcp<-coords(dda.top20.roc.pred,x=bct$threshold,
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bcp)<-'validation'
dda.top20.best.threshold<-as.data.frame(t(rbind(bct,bcp)))
pander(dda.top20.best.threshold)
```

## Top 10

```{r dda.top10.get.train,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(dda.res.top10[[1]])
labM.dda.top10<-matrix(train.md$diagnosis,nrow = length(train.md$diagnosis),ncol = length(dda.res.top10))
trainL.dda.top10<-lapply(dda.res.top10,
                   function(.m)analyzePeaks::getPrediction(train.fm,.m))
terrL.dda.top10<-lapply(trainL.dda.top10,
                   function(.x)diagnosticErrors(
                     confusionMatrix(train.md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
terrM.dda.top10<-as.data.frame(do.call(rbind,terrL.dda.top10))
train.probL.dda.top10<-lapply(trainL.dda.top10,function(.x).x$probII)
train.probM.dda.top10<-do.call(cbind,train.probL.dda.top10)
train.auc<- caTools::colAUC(train.probM.dda.top10,train.cls,plotROC = TRUE)
terrM.dda.top10$AUC<-t(train.auc)
terrM.dda.top10<-cbind(
  data.frame(mIdx=1:length(dda.res.top10),
             type='DDA',
             nFeatures=length(mz)),
  terrM.dda.top10)
```

```{r dda.top10.get.predictions,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(dda.res.top10[[1]])
labM.dda.top10<-matrix(md$diagnosis,nrow = length(md$diagnosis),ncol = length(dda.res.top10))
predL.dda.top10<-lapply(dda.res.top10,
                   function(.m)analyzePeaks::getPrediction(predict.fm,.m))
derrL.dda.top10<-lapply(predL.dda.top10,
                   function(.x)diagnosticErrors(
                     confusionMatrix(md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
derrM.dda.top10<-as.data.frame(do.call(rbind,derrL.dda.top10))
probL.dda.top10<-lapply(predL.dda.top10,function(.x).x$probII)
probM.dda.top10<-do.call(cbind,probL.dda.top10)
auc<- caTools::colAUC(probM.dda.top10,cls,plotROC = TRUE)
derrM.dda.top10$AUC<-t(auc)
derrM.dda.top10<-cbind(    
  data.frame(mIdx=1:length(dda.res.top10),
             type='DDA',
             nFeatures=length(mz)),             
  derrM.dda.top10)
```

```{r dda.top10.plots}
p1<-qplot(acc,AUC,data = derrM.dda.top10)
p2<-qplot(sens,AUC,data = derrM.dda.top10)
p3<-qplot(spec,AUC,data = derrM.dda.top10)
p4<-qplot(sens,spec,data = derrM.dda.top10)

multiplot(p1,p2,p3,p4,cols = 2)
```

```{r dda.top10.table}
ridx<-unique(c(
  which.max(derrM.dda.top10$acc),
  which.max(derrM.dda.top10$sens),
  which.max(derrM.dda.top10$spec),
  which.max(derrM.dda.top10$AUC)))
pander(derrM.dda.top10[ridx,])
```


```{r dda.top10.analyse.best.model.train}
idxBest<-which.max(terrM.dda.top10$AUC)
dda.top10.best<-dda.res.top10[[idxBest]]
t<-trainL.dda.top10[[idxBest]]
t$diag<-as.character(train.cls)
train.best[['dda.top10']]<-t$probII
dda.top10.roc.train<-roc(t$diag,t$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bct<-coords(dda.top10.roc.train,"best",
            best.method='c',
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bct)<-'training'
```

```{r dda.top10.analyse.best.model.test}
p<-predL.dda.top10[[idxBest]]
p$diag<-as.character(cls)
test.best[['dda.top10']]<-p$probII
dda.top10.roc.pred<-roc(p$diag,p$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bcp<-coords(dda.top10.roc.pred,x=bct$threshold,
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bcp)<-'validation'
dda.top10.best.threshold<-as.data.frame(t(rbind(bct,bcp)))
pander(dda.top10.best.threshold)
```


# Shrinkage Discriminative Analysis

## Full dataset
```{r lda.full.get.train,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(lda.res.full[[1]])
labM.lda.full<-matrix(train.md$diagnosis,nrow = length(train.md$diagnosis),ncol = length(lda.res.full))
trainL.lda.full<-lapply(lda.res.full,
                   function(.m)analyzePeaks::getPrediction(train.fm,.m))
terrL.lda.full<-lapply(trainL.lda.full,
                   function(.x)diagnosticErrors(
                     confusionMatrix(train.md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
terrM.lda.full<-as.data.frame(do.call(rbind,terrL.lda.full))
train.probL.lda.full<-lapply(trainL.lda.full,function(.x).x$probII)
train.probM.lda.full<-do.call(cbind,train.probL.lda.full)
train.auc<- caTools::colAUC(train.probM.lda.full,train.cls,plotROC = TRUE)
terrM.lda.full$AUC<-t(train.auc)
terrM.lda.full<-cbind(
  data.frame(mIdx=1:length(lda.res.full),
             type='lda',
             nFeatures=length(mz)),
  terrM.lda.full)
```

```{r lda.full.get.predictions,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(lda.res.full[[1]])
labM.lda.full<-matrix(md$diagnosis,nrow = length(md$diagnosis),ncol = length(lda.res.full))
predL.lda.full<-lapply(lda.res.full,
                   function(.m)analyzePeaks::getPrediction(predict.fm,.m))
derrL.lda.full<-lapply(predL.lda.full,
                   function(.x)diagnosticErrors(
                     confusionMatrix(md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
derrM.lda.full<-as.data.frame(do.call(rbind,derrL.lda.full))
probL.lda.full<-lapply(predL.lda.full,function(.x).x$probII)
probM.lda.full<-do.call(cbind,probL.lda.full)
auc<- caTools::colAUC(probM.lda.full,cls,plotROC = TRUE)
derrM.lda.full$AUC<-t(auc)
derrM.lda.full<-cbind(
  data.frame(mIdx=1:length(lda.res.full),
             type='SDA',
             nFeatures=length(mz)),
  derrM.lda.full)
```

```{r lda.full.plots}
p1<-qplot(acc,AUC,data = derrM.lda.full)
p2<-qplot(sens,AUC,data = derrM.lda.full)
p3<-qplot(spec,AUC,data = derrM.lda.full)
p4<-qplot(sens,spec,data = derrM.lda.full)

multiplot(p1,p2,p3,p4,cols = 2)
```

```{r lda.full.table}
ridx<-unique(c(
  which.max(derrM.lda.full$acc),
  which.max(derrM.lda.full$sens),
  which.max(derrM.lda.full$spec),
  which.max(derrM.lda.full$AUC)))
pander(derrM.lda.full[ridx,])
```

```{r lda.full.analyse.best.model.train}
idxBest<-which.max(terrM.lda.full$AUC)
lda.full.best<-lda.res.full[[idxBest]]
t<-trainL.lda.full[[idxBest]]
t$diag<-as.character(train.cls)
train.best[['lda.full']]t<-t$probII
lda.full.roc.train<-roc(t$diag,t$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bct<-coords(lda.full.roc.train,"best",
            best.method='c',
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bct)<-'training'
```

```{r lda.full.analyse.best.model.test}
p<-predL.lda.full[[idxBest]]
p$diag<-as.character(cls)
test.best[['lda.full']]<-p$probII
lda.full.roc.pred<-roc(p$diag,p$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bcp<-coords(lda.full.roc.pred,x=bct$threshold,
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bcp)<-'validation'
lda.full.best.threshold<-as.data.frame(t(rbind(bct,bcp)))
pander(lda.full.best.threshold)
```

## Top 20
```{r lda.top20.get.train,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(lda.res.top20[[1]])
labM.lda.top20<-matrix(train.md$diagnosis,nrow = length(train.md$diagnosis),ncol = length(lda.res.top20))
trainL.lda.top20<-lapply(lda.res.top20,
                   function(.m)analyzePeaks::getPrediction(train.fm,.m))
terrL.lda.top20<-lapply(trainL.lda.top20,
                   function(.x)diagnosticErrors(
                     confusionMatrix(train.md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
terrM.lda.top20<-as.data.frame(do.call(rbind,terrL.lda.top20))
train.probL.lda.top20<-lapply(trainL.lda.top20,function(.x).x$probII)
train.probM.lda.top20<-do.call(cbind,train.probL.lda.top20)
train.auc<- caTools::colAUC(train.probM.lda.top20,train.cls,plotROC = TRUE)
terrM.lda.top20$AUC<-t(train.auc)
terrM.lda.top20<-cbind(
  data.frame(mIdx=1:length(lda.res.top20),
             type='lda',
             nFeatures=length(mz)),
  terrM.lda.top20)
```

```{r lda.top20.get.predictions,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(lda.res.top20[[1]])
labM.lda.top20<-matrix(md$diagnosis,nrow = length(md$diagnosis),ncol = length(lda.res.top20))
predL.lda.top20<-lapply(lda.res.top20,
                   function(.m)analyzePeaks::getPrediction(predict.fm,.m))
derrL.lda.top20<-lapply(predL.lda.top20,
                   function(.x)diagnosticErrors(
                     confusionMatrix(md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
derrM.lda.top20<-as.data.frame(do.call(rbind,derrL.lda.top20))
probL.lda.top20<-lapply(predL.lda.top20,function(.x).x$probII)
probM.lda.top20<-do.call(cbind,probL.lda.top20)
auc<- caTools::colAUC(probM.lda.top20,cls,plotROC = TRUE)
derrM.lda.top20$AUC<-t(auc)
derrM.lda.top20<-cbind(    
  data.frame(mIdx=1:length(lda.res.top20),
             type='SDA',
             nFeatures=length(mz)),
  derrM.lda.top20)
```

```{r lda.top20.plots}
p1<-qplot(acc,AUC,data = derrM.lda.top20)
p2<-qplot(sens,AUC,data = derrM.lda.top20)
p3<-qplot(spec,AUC,data = derrM.lda.top20)
p4<-qplot(sens,spec,data = derrM.lda.top20)

multiplot(p1,p2,p3,p4,cols = 2)
```

```{r lda.top20.table}
ridx<-unique(c(
  which.max(derrM.lda.top20$acc),
  which.max(derrM.lda.top20$sens),
  which.max(derrM.lda.top20$spec),
  which.max(derrM.lda.top20$AUC)))
pander(derrM.lda.top20[ridx,])
```

```{r lda.top20.analyse.best.model.train}
idxBest<-which.max(terrM.lda.top20$AUC)
lda.top20.best<-lda.res.top20[[idxBest]]
t<-trainL.lda.top20[[idxBest]]
t$diag<-as.character(train.cls)
train.best[['lda.top20']]<-t$probII
lda.top20.roc.train<-roc(t$diag,t$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bct<-coords(lda.top20.roc.train,"best",
            best.method='c',
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bct)<-'training'
```

```{r lda.top20.analyse.best.model.test}
p<-predL.lda.top20[[idxBest]]
p$diag<-as.character(cls)
test.best[['lda.top20']]<-p$probII
lda.top20.roc.pred<-roc(p$diag,p$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bcp<-coords(lda.top20.roc.pred,x=bct$threshold,
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bcp)<-'validation'
lda.top20.best.threshold<-as.data.frame(t(rbind(bct,bcp)))
pander(lda.top20.best.threshold)
```

## Top 10
```{r lda.top10.get.train,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(lda.res.top10[[1]])
labM.lda.top10<-matrix(train.md$diagnosis,nrow = length(train.md$diagnosis),ncol = length(lda.res.top10))
trainL.lda.top10<-lapply(lda.res.top10,
                   function(.m)analyzePeaks::getPrediction(train.fm,.m))
terrL.lda.top10<-lapply(trainL.lda.top10,
                   function(.x)diagnosticErrors(
                     confusionMatrix(train.md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
terrM.lda.top10<-as.data.frame(do.call(rbind,terrL.lda.top10))
train.probL.lda.top10<-lapply(trainL.lda.top10,function(.x).x$probII)
train.probM.lda.top10<-do.call(cbind,train.probL.lda.top10)
train.auc<- caTools::colAUC(train.probM.lda.top10,train.cls,plotROC = TRUE)
terrM.lda.top10$AUC<-t(train.auc)
terrM.lda.top10<-cbind(
  data.frame(mIdx=1:length(lda.res.top10),
             type='lda',
             nFeatures=length(mz)),
  terrM.lda.top10)
```

```{r lda.top10.get.predictions,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(lda.res.top10[[1]])
labM.lda.top10<-matrix(md$diagnosis,nrow = length(md$diagnosis),ncol = length(lda.res.top10))
predL.lda.top10<-lapply(lda.res.top10,
                   function(.m)analyzePeaks::getPrediction(predict.fm,.m))
derrL.lda.top10<-lapply(predL.lda.top10,
                   function(.x)diagnosticErrors(
                     confusionMatrix(md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
derrM.lda.top10<-as.data.frame(do.call(rbind,derrL.lda.top10))
probL.lda.top10<-lapply(predL.lda.top10,function(.x).x$probII)
probM.lda.top10<-do.call(cbind,probL.lda.top10)
auc<- caTools::colAUC(probM.lda.top10,cls,plotROC = TRUE)
derrM.lda.top10$AUC<-t(auc)
derrM.lda.top10<-cbind(    
  data.frame(mIdx=1:length(lda.res.top10),
             type='SDA',
             nFeatures=dim(predict.fm)[2]),
  derrM.lda.top10)
```

```{r lda.top10.plots}
p1<-qplot(acc,AUC,data = derrM.lda.top10)
p2<-qplot(sens,AUC,data = derrM.lda.top10)
p3<-qplot(spec,AUC,data = derrM.lda.top10)
p4<-qplot(sens,spec,data = derrM.lda.top10)

multiplot(p1,p2,p3,p4,cols = 2)
```

```{r lda.top10.table}
ridx<-unique(c(
  which.max(derrM.lda.top10$acc),
  which.max(derrM.lda.top10$sens),
  which.max(derrM.lda.top10$spec),
  which.max(derrM.lda.top10$AUC)))
pander(derrM.lda.top10[ridx,])
```


```{r lda.top10.analyse.best.model.train}
idxBest<-which.max(terrM.lda.top10$AUC)
lda.top10.best<-lda.res.top10[[idxBest]]
t<-trainL.lda.top10[[idxBest]]
t$diag<-as.character(train.cls)
train.best[['lda.top10']]<-t$probII
lda.top10.roc.train<-roc(t$diag,t$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bct<-coords(lda.top10.roc.train,"best",
            best.method='c',
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bct)<-'training'
```

```{r lda.top10.analyse.best.model.test}
p<-predL.lda.top10[[idxBest]]
p$diag<-as.character(cls)
test.best[['lda.top10']]<-p$probIIlda.top10.roc.pred<-roc(p$diag,p$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bcp<-coords(lda.top10.roc.pred,x=bct$threshold,
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bcp)<-'validation'
lda.top10.best.threshold<-as.data.frame(t(rbind(bct,bcp)))
pander(lda.top10.best.threshold)
```


# LASSO

## Full dataset
```{r lasso.full.get.train,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(lasso.res.full[[1]])
labM.lasso.full<-matrix(train.md$diagnosis,nrow = length(train.md$diagnosis),ncol = length(lasso.res.full))
trainL.lasso.full<-lapply(lasso.res.full,
                   function(.m)analyzePeaks::getPrediction(train.fm,.m))
terrL.lasso.full<-lapply(trainL.lasso.full,
                   function(.x)diagnosticErrors(
                     confusionMatrix(train.md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
terrM.lasso.full<-as.data.frame(do.call(rbind,terrL.lasso.full))
train.probL.lasso.full<-lapply(trainL.lasso.full,function(.x).x$probII)
train.probM.lasso.full<-do.call(cbind,train.probL.lasso.full)
train.auc<- caTools::colAUC(train.probM.lasso.full,train.cls,plotROC = TRUE)
terrM.lasso.full$AUC<-t(train.auc)
terrM.lasso.full<-cbind(
  data.frame(mIdx=1:length(lasso.res.full),
             type='lasso',
             nFeatures=length(mz)),
  terrM.lasso.full)
```

```{r lasso.full.get.predictions,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(lasso.res.full[[1]])
labM.lasso.full<-matrix(md$diagnosis,nrow = length(md$diagnosis),ncol = length(lasso.res.full))
predL.lasso.full<-lapply(lasso.res.full,
                   function(.m)analyzePeaks::getPrediction(predict.fm,.m))
derrL.lasso.full<-lapply(predL.lasso.full,
                   function(.x)diagnosticErrors(
                     confusionMatrix(md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
derrM.lasso.full<-as.data.frame(do.call(rbind,derrL.lasso.full))
probL.lasso.full<-lapply(predL.lasso.full,function(.x).x$probII)
probM.lasso.full<-do.call(cbind,probL.lasso.full)
auc<- caTools::colAUC(probM.lasso.full,cls,plotROC = TRUE)
derrM.lasso.full$AUC<-t(auc)
derrM.lasso.full<-cbind(
  data.frame(mIdx=1:length(lasso.res.full),
             type='LASSO',
             nFeatures=length(mz)),
  derrM.lasso.full)
```

```{r lasso.full.plots}
p1<-qplot(acc,AUC,data = derrM.lasso.full)
p2<-qplot(sens,AUC,data = derrM.lasso.full)
p3<-qplot(spec,AUC,data = derrM.lasso.full)
p4<-qplot(sens,spec,data = derrM.lasso.full)

multiplot(p1,p2,p3,p4,cols = 2)
```

```{r lasso.full.table}
ridx<-unique(c(
  which.max(derrM.lasso.full$acc),
  which.max(derrM.lasso.full$sens),
  which.max(derrM.lasso.full$spec),
  which.max(derrM.lasso.full$AUC)))
pander(derrM.lasso.full[ridx,])
```

```{r lasso.full.analyse.best.model.train}
idxBest<-which.max(terrM.lasso.full$AUC)
lasso.full.best<-lasso.res.full[[idxBest]]
t<-trainL.lasso.full[[idxBest]]
t$diag<-as.character(train.cls)
train.best[['lasso.full']]<-t$probII
lasso.full.roc.train<-roc(t$diag,t$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bct<-coords(lasso.full.roc.train,"best",
            best.method='c',
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bct)<-'training'
```

```{r lasso.full.analyse.best.model.test}
p<-predL.lasso.full[[idxBest]]
p$diag<-as.character(cls)
test.best[['lasso.full']]<-p$probII
lasso.full.roc.pred<-roc(p$diag,p$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bcp<-coords(lasso.full.roc.pred,x=bct$threshold,
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bcp)<-'validation'
lasso.full.best.threshold<-as.data.frame(t(rbind(bct,bcp)))
pander(lasso.full.best.threshold)
```

## Top 20
```{r lasso.top20.get.train,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(lasso.res.top20[[1]])
labM.lasso.top20<-matrix(train.md$diagnosis,nrow = length(train.md$diagnosis),ncol = length(lasso.res.top20))
trainL.lasso.top20<-lapply(lasso.res.top20,
                   function(.m)analyzePeaks::getPrediction(train.fm,.m))
terrL.lasso.top20<-lapply(trainL.lasso.top20,
                   function(.x)diagnosticErrors(
                     confusionMatrix(train.md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
terrM.lasso.top20<-as.data.frame(do.call(rbind,terrL.lasso.top20))
train.probL.lasso.top20<-lapply(trainL.lasso.top20,function(.x).x$probII)
train.probM.lasso.top20<-do.call(cbind,train.probL.lasso.top20)
train.auc<- caTools::colAUC(train.probM.lasso.top20,train.cls,plotROC = TRUE)
terrM.lasso.top20$AUC<-t(train.auc)
terrM.lasso.top20<-cbind(
  data.frame(mIdx=1:length(lasso.res.top20),
             type='lasso',
             nFeatures=length(mz)),
  terrM.lasso.top20)
```

```{r lasso.top20.get.predictions,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(lasso.res.top20[[1]])
labM.lasso.top20<-matrix(md$diagnosis,nrow = length(md$diagnosis),ncol = length(lasso.res.top20))
predL.lasso.top20<-lapply(lasso.res.top20,
                   function(.m)analyzePeaks::getPrediction(predict.fm,.m))
derrL.lasso.top20<-lapply(predL.lasso.top20,
                   function(.x)diagnosticErrors(
                     confusionMatrix(md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
derrM.lasso.top20<-as.data.frame(do.call(rbind,derrL.lasso.top20))
probL.lasso.top20<-lapply(predL.lasso.top20,function(.x).x$probII)
probM.lasso.top20<-do.call(cbind,probL.lasso.top20)
auc<- caTools::colAUC(probM.lasso.top20,cls,plotROC = TRUE)
derrM.lasso.top20$AUC<-t(auc)
derrM.lasso.top20<-cbind(
    data.frame(mIdx=1:length(lasso.res.top20),
             type='LASSO',
             nFeatures=length(mz)),
    derrM.lasso.top20)
```

```{r lasso.top20.plots}
p1<-qplot(acc,AUC,data = derrM.lasso.top20)
p2<-qplot(sens,AUC,data = derrM.lasso.top20)
p3<-qplot(spec,AUC,data = derrM.lasso.top20)
p4<-qplot(sens,spec,data = derrM.lasso.top20)

multiplot(p1,p2,p3,p4,cols = 2)
```

```{r lasso.top20.table}
ridx<-unique(c(
  which.max(derrM.lasso.top20$acc),
  which.max(derrM.lasso.top20$sens),
  which.max(derrM.lasso.top20$spec),
  which.max(derrM.lasso.top20$AUC)))
pander(derrM.lasso.top20[ridx,])
```

```{r lasso.top20.analyse.best.model.train}
idxBest<-which.max(terrM.lasso.top20$AUC)
lasso.top20.best<-lasso.res.top20[[idxBest]]
t<-trainL.lasso.top20[[idxBest]]
t$diag<-as.character(train.cls)
train.best[['lasso.top20']]<-t$probII
lasso.top20.roc.train<-roc(t$diag,t$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bct<-coords(lasso.top20.roc.train,"best",
            best.method='c',
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bct)<-'training'
```

```{r lasso.top20.analyse.best.model.test}
p<-predL.lasso.top20[[idxBest]]
p$diag<-as.character(cls)
test.best[['lasso.top20']]<-p$probII
lasso.top20.roc.pred<-roc(p$diag,p$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bcp<-coords(lasso.top20.roc.pred,x=bct$threshold,
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bcp)<-'validation'
lasso.top20.best.threshold<-as.data.frame(t(rbind(bct,bcp)))
pander(lasso.top20.best.threshold)
```

## Top 10
```{r lasso.top10.get.train,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(lasso.res.top10[[1]])
labM.lasso.top10<-matrix(train.md$diagnosis,nrow = length(train.md$diagnosis),ncol = length(lasso.res.top10))
trainL.lasso.top10<-lapply(lasso.res.top10,
                   function(.m)analyzePeaks::getPrediction(train.fm,.m))
terrL.lasso.top10<-lapply(trainL.lasso.top10,
                   function(.x)diagnosticErrors(
                     confusionMatrix(train.md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
terrM.lasso.top10<-as.data.frame(do.call(rbind,terrL.lasso.top10))
train.probL.lasso.top10<-lapply(trainL.lasso.top10,function(.x).x$probII)
train.probM.lasso.top10<-do.call(cbind,train.probL.lasso.top10)
train.auc<- caTools::colAUC(train.probM.lasso.top10,train.cls,plotROC = TRUE)
terrM.lasso.top10$AUC<-t(train.auc)
terrM.lasso.top10<-cbind(
  data.frame(mIdx=1:length(lasso.res.top10),
             type='lasso',
             nFeatures=length(mz)),
  terrM.lasso.top10)
```

```{r lasso.top10.get.predictions,fig.width=8.5,fig.height=8.5,dev='png'} 
mz<-getReferenceMZ(lasso.res.top10[[1]])
labM.lasso.top10<-matrix(md$diagnosis,nrow = length(md$diagnosis),ncol = length(lasso.res.top10))
predL.lasso.top10<-lapply(lasso.res.top10,
                   function(.m)analyzePeaks::getPrediction(predict.fm,.m))
derrL.lasso.top10<-lapply(predL.lasso.top10,
                   function(.x)diagnosticErrors(
                     confusionMatrix(md$diagnosis, 
                                     .x$class, 
                                     negative=32)))
derrM.lasso.top10<-as.data.frame(do.call(rbind,derrL.lasso.top10))
probL.lasso.top10<-lapply(predL.lasso.top10,function(.x).x$probII)
probM.lasso.top10<-do.call(cbind,probL.lasso.top10)
auc<- caTools::colAUC(probM.lasso.top10,cls,plotROC = TRUE)
derrM.lasso.top10$AUC<-t(auc)
derrM.lasso.top10<-cbind(   
  data.frame(mIdx=1:length(lasso.res.top10),
             type='LASSO',
             nFeatures=length(mz)),
  derrM.lasso.top10)
```

```{r lasso.top10.plots}
p1<-qplot(acc,AUC,data = derrM.lasso.top10)
p2<-qplot(sens,AUC,data = derrM.lasso.top10)
p3<-qplot(spec,AUC,data = derrM.lasso.top10)
p4<-qplot(sens,spec,data = derrM.lasso.top10)

multiplot(p1,p2,p3,p4,cols = 2)
```

```{r lasso.top10.table}
ridx<-unique(c(
  which.max(derrM.lasso.top10$acc),
  which.max(derrM.lasso.top10$sens),
  which.max(derrM.lasso.top10$spec),
  which.max(derrM.lasso.top10$AUC)))
pander(derrM.lasso.top10[ridx,])
```




```{r lasso.top10.analyse.best.model.train}
idxBest<-which.max(terrM.lasso.top10$AUC)
lasso.top10.best<-lasso.res.top10[[idxBest]]
t<-trainL.lasso.top10[[idxBest]]
t$diag<-as.character(train.cls)
train.best[['lasso.top10']]<-t$probII
lasso.top10.roc.train<-roc(t$diag,t$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bct<-coords(lasso.top10.roc.train,"best",
            best.method='c',
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bct)<-'training'
```

```{r lasso.top10.analyse.best.model.test}
p<-predL.lasso.top10[[idxBest]]
p$diag<-as.character(cls)
test.best[['lasso.top10']]<-p$probII
lasso.top10.roc.pred<-roc(p$diag,p$probII,
                  smoothed = TRUE,ci=TRUE, 
                  ci.alpha=0.9, 
                  stratified=FALSE,plot=TRUE, 
                  auc.polygon=TRUE, max.auc.polygon=TRUE, 
                  grid=TRUE,print.auc=TRUE, 
                  show.thres=TRUE)
bcp<-coords(lasso.top10.roc.pred,x=bct$threshold,
            transpose = FALSE,
            ret=c("threshold",'tn','tp',
                  'fn','fp','specificity',
                  'sensitivity','precision',
                  'accuracy','youden',
                  'closest.topleft'))
rownames(bcp)<-'validation'
lasso.top10.best.threshold<-as.data.frame(t(rbind(bct,bcp)))
pander(lasso.top10.best.threshold)
```


# Combine predictions
```{r combine.predictions}
scheme <- c("simple",  "variance based", "ols", "robust", "cls", "best")
combine_f <- list()
combine_res<-as.data.frame(
  matrix(0,ncol=length(scheme),
         nrow = 2,
         dimnames = list(c('train','test'),
                         scheme)))
train_err<-sapply(train.best,getRMSD,obs=train.cls)
test_err<-sapply(test.best,getRMSD,obs=cls)
ind_err<-as.data.frame(rbind(train_err,test_err))
rownames(ind_err)<-c('training','validation')
m.train<-do.call(cbind,train.best)
m.test<-do.call(cbind,test.best)
for (i in scheme) {
  combine_f[[i]] <- Forecast_comb(obs = (as.numeric(train.cls)-1),
                                  fhat = m.train,
                                  fhat_new=m.test,
                                  Averaging_scheme = i)
  combine_res[1,i] <- round(
    sqrt(mean((combine_f[[i]]$fitted - 
            (as.numeric(train.cls)-1))^2)), 
    3)
  combine_res[2,i] <- round(
    sqrt(mean((combine_f[[i]]$pred - 
                 (as.numeric(cls)-1))^2)), 
    3)
}
pander(ind_err)
pander(combine_res)
```

# Appendix {.tabset}
## Functions
```{r functions, eval=FALSE, include=TRUE}
```
```{r queries, eval=FALSE, include=TRUE}
```

## Setup R
```{r setup, eval=FALSE}
```

## Versions
### Document version
```{r docVersion, echo=FALSE, results='asis', cache=FALSE}
cat(params$version)
```

### Session Info
```{r sessionInfo, echo=FALSE, results='asis', class='text', warning=FALSE}
si<-devtools::session_info()
cat('Platform\n\n')
pander::pander(si$platform)
cat('Packages\n\n')
knitr::kable(as.data.frame(si$packages)[,c('ondiskversion','loadedversion','date','source')],align = c('l','l'))
```

