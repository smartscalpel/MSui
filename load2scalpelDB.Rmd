---
title: "load2scalpelDB"
author: "Anatoly Sorokin"
date: '`r format(Sys.time(), "%d.%m.%Y")`'
output:
  pdf_document:
    keep_tex: yes
    number_sections: yes
  html_document: default
params:
  format: !r if(opts_knit$get("rmarkdown.pandoc.to") == 'html') c('screen', 'print')
    else 'print'
  version: !r if(nchar(Sys.which("git"))) system("git describe --long --dirty --abbrev=10  --tags  --always",
    intern=TRUE) else date()
header-includes:
- \usepackage[T2A]{fontenc}
- \usepackage[utf8]{inputenc}
- \usepackage[english,russian]{babel}
- \usepackage{grffile}
- \usepackage{rotating}
- \usepackage{caption}
- \usepackage{longtable}
- \usepackage{lscape}
---
```{r loadPackages, include=FALSE, cache=FALSE}
## load additional packages in this chunk
library(pander)
library(knitr)
#library('Matrix')
library(ggplot2)
library(data.table)
#library(plyr)
library(xtable)
#library(xcms)
#library("FactoMineR")
#library(cluster)
#library(dendextend)
#library(factoextra)
#library(corrplot)
library(ncdf4)
#library("PerformanceAnalytics")
#library("pvclust")
#library("sda")
library(RColorBrewer)
library(MALDIquant)
library(MALDIquantForeign)
library(DBI)
library(MonetDB.R)
ticThreshold<-0.01
absTicThreshold<-1000
```

```{r setup, include=FALSE, cache=FALSE}
## This chunk should contain global configuration commands.
## Use this to set knitr options and related things. Everything
## in this chunk will be included in an appendix to document the
## configuration used.
#output <- opts_knit$get("rmarkdown.pandoc.to")
opts_knit$set(stop_on_error = 2L)

## By default R code is only included in HTML versions of the report
## (where it can be collapsed). You can generate a PDF version
## using rmarkdown::pdf_document to get a copy for print. Extensive
## chunks of R code may or may not be desired in /hat setting. If you
## want them simply change the following arguments to `echo = TRUE`.
## In either case the default can be overwritten for individual chunks.
#opts_chunk$set(echo = output=="html")
#opts_chunk$set(warning = output=="html")
#opts_chunk$set(message = output=="html")

## Cache options
opts_chunk$set(cache=FALSE)

## Figure options
## Set default figure format
#options(reportmd.figure.format=params$format)

## Set 'hide.fig.code' to FALSE to include code chunks that
## produce Figures in the output. Note that this affects all chunks
## that provide a figure caption.
opts_chunk$set(hold=TRUE, hide.fig.code=FALSE)

## Set up default plotting options for different formats.
## These can be overwritten for individual chunks
#interactiveFig()
#screenFig()
#printFig()

## Pander options
panderOptions("digits", 3)
panderOptions("table.split.table", 160)

## Configure Figure and Table lables
#options(figcap.prefix = "Figure", figcap.sep = ":", figcap.prefix.highlight = "**")
#options(tabcap.prefix = "Table", tabcap.sep = ":", tabcap.prefix.highlight = "**")

## Install required knitr hooks
#installHooks()
```

```{r functions, include=FALSE}
## Custom functions used in the analysis should go into this chunk.
## They will be listed in their own section of the appendix.

##==================== SQL queries ====================##
insertComment<-paste('insert into comment(dt,comment,author) values (now(),?,?)')
getCommentID<-'SELECT ID FROM comment where comment=?'
insertCommentRef<-paste('insert into spectrum_comment(spectrumid,commentid) values (?,?)')
insertSpectrum<-paste("INSERT INTO spectrum ",
 "  (SampleTumorID, ",
 "  SampleTumorPatientID, ",
 "  SampleID, ",
 "  ResolutionID, ",
 "  Solvent, ",
 "  Device, ",
 "  dt, ",
 "  FileName, ",
 "  ionsource, ",
 "  mode) ",
 "VALUES (?,?,?,?,?,?,now(),?,?,?);")
getSpecID<-'SELECT ID FROM spectrum where filename=?'
getSample<-'select s.id,s.label as name, \'tissue: "\'||t.label||\'"; patient: "\'|| p.emsid||\'"\' as description from smpl s,tissue t, patient p where s.id=? and t.id=s.tumorid and s.tumorpatientid=p.id;'
insertScan<-paste("INSERT INTO scan",
"  (SpectrumID, ",
"  num, ",
"  rt, ",
"  tic) ",
"VALUES (?, ?, ?, ?);")
getScanID<-'SELECT ID FROM scan where spectrumid=? and num=?'

##==================== Functions ====================##
writeDTsignal<-function(sp,specID,fname){
  md<-metaData(sp)
  #cat('Writing scan',md$number,md$retentionTime,'\n')
  resDF<-data.table(spec=specID,
                    num=md$number,
                    mz=sp@mass,
                    intensity=sp@intensity)
  if(file.exists(fname)){
  	app=TRUE
  }else{
  	app=FALSE
  }
  fwrite(resDF,file=fname,col.names=FALSE,append=app,quote=FALSE,sep='|',row.names=FALSE,na='')
}

writeDTpeak<-function(p,specID,tic,fname){
  md<-metaData(p)
  #cat('Writing scan',md$number,md$retentionTime,'\n')
  resDF<-data.table(spec=specID,
                    num=md$number,
                    mz=p@mass,
                    intensity=tic[md$number]*p@intensity,
                    norm2tic=p@intensity,snr=p@snr)
  if(file.exists(fname)){
  	app=TRUE
  }else{
  	app=FALSE
  }
  fwrite(resDF,file=fname,col.names=FALSE,append=app,quote=FALSE,sep='|',row.names=FALSE,na='')
}

```

```
{r oblig.par}
dbname = "msinvent"
usr='msinvent'
pwd='msinvent'
dtPath = '/Volumes/AS_WD_HFS/Scalpel/DBData/'
cdf.file='/Users/lptolik/Yandex.Disk.localized/BD_cdf/1_02_495_MetCl_2_FT100k.cdf'
devID<-1 #Device
solID<-6 #Solvent
isID<-1 # ionsource
resID<-1 #ResolutionID
smplID<-1 #SampleID
stID<-1 #SampleTumorID
stpID<-1 #SampleTumorPatientID
nMode<-1 #Negative mode
```

# Read data
Before running the code a number of variables should be setted for appropriate data loading:
 
 1. the path to the folder where data will be moved after upload *dtPath* 
 2. the references to device *devID*, solvent *solID*, ion source *isID*, resolution *resID*, mode *nMode*
 3. the name of the database *dbname*
 4. user/password for teh database: *usr* and *pwd*
 

Для работы необходим параметр `cdf.file`, который содержит полный путь к обрабатываемому файлу. В базу будут загружено содержимое файла `cdf.file`

```{r check.values}
if(!(exists('dbname')&
     exists('usr')&
     exists('pwd')&
#     exists('dtPath')&
     exists('devID')&
     exists('solID')&
     exists('isID')&
     exists('resID')&
     exists('smplID')&
     exists('stID')&
     exists('stpID')&
     exists('nMode')&
     exists('cdf.file'))){
  stop('not all obligatory parameters are provided\n')
}
if(!exists('halfWindowSize')){
  halfWindowSize<-3 # best suited for centroided data
}
ncMD<- ncatt_get(nc_open(cdf.file),0)
experimentData<-ncMD$experiment_date_time_stamp
fileData<-ncMD$netcdf_file_date_time_stamp
origFilePath<-ncMD$source_file_reference
comment<-ncMD$administrative_comments
```


# Загрузка данных с помощью MALDIquant

Текущее значение параметра `cdf.file`:

`r cdf.file`

```{r load.cdf,cache=TRUE}
spectra<-import(cdf.file,verbose=TRUE)
if(any(sapply(spectra, MALDIquant::isEmpty))){
  spectra<-spectra[!sapply(spectra, MALDIquant::isEmpty)]
}
mzWidth<-sapply(spectra, function(.x)diff(range(.x@mass)))
if(any(mzWidth<0.2*max(mzWidth))){
  spectra<-spectra[mzWidth>=0.2*max(mzWidth)]
}
#hist(sapply(spectra, length))
tic<-sapply(spectra,totalIonCurrent)
eic300<-sapply(trim(spectra,range = c(0,350)),totalIonCurrent)
eic1000<-sapply(trim(spectra,range = c(400,1000)),totalIonCurrent)
time<-sapply(spectra,function(.x)metaData(.x)$retentionTime)
qtic<-quantile(tic,probs = seq(0, 1, 0.1),names = TRUE)
qth<-max(absTicThreshold,quantile(tic,probs = ticThreshold))
#plot(xraw@tic,tic)
plot(tic)
abline(h = qth)
#spectra <- trim(spectra,range = mzrange)
```

# Load data to DB
```{r db.connect}
conn <- dbConnect(MonetDB.R::MonetDB(), 
                  dbname = dbname,
                  user=usr,password=pwd)
spectrumID<-dbGetQuery(conn,getSpecID,basename(cdf.file))
proceedFile<-(dim(spectrumID)[1]==0)
#proceedFile<-TRUE
devices<-dbReadTable(conn,'device')
idxDev<-which(devices$id==devID)
solvents<-dbReadTable(conn,'solvent')
idxSol<-which(solvents$id==solID)
ionSources<-dbReadTable(conn,'ionsource')
idxIS<-which(ionSources$id==isID)
resolutions<-dbReadTable(conn,'resolution')
idxRes<-which(resolutions$id==resID)
modes<-dbReadTable(conn,'mode')
idxMode<-which(modes$id==nMode)
smplID<-1 #SampleID
sample<-dbGetQuery(conn,getSample,smplID)
stID<-1 #SampleTumorID
stpID<-1 #SampleTumorPatientID
note<-paste('exDT:',experimentData,'\nfileDT:',
            fileData,'\norigFile:',
            origFilePath,'\ncomment:',comment)
parName<-c('Sample','Device','Ion source','Resolution','Mode','Solvent')
resDF<-cbind(data.frame(Parameter=parName),
             rbind(sample,
                   devices[idxDev,c(1,2,4)],
                   ionSources[idxIS,],
                   resolutions[idxRes,],
                   modes[idxMode,],
                   data.frame(id=solvents$id[idxSol],
                              name=solvents$name[idxSol],
                              description=solvents$composition[idxSol])
                   )
             )
```


The data loaded with the following properties:
```{r prop.table, eval=proceedFile}
kable(resDF, format = "latex", caption = 'Predefined parameters for load', row.names=FALSE, booktabs=TRUE)
```
```{r already.loaded,eval=!proceedFile}
cat('The file with name \n"',cdf.file,'"\n already loaded into the database\n')
```
 

## Spectrum
```{r insert.spectrum, eval=proceedFile}
rs<-dbSendStatement(conn,insertSpectrum,stID,stpID,smplID,resID,solID,devID,basename(cdf.file),isID,nMode)
    dbHasCompleted(rs)
    dbGetRowsAffected(rs)
    dbClearResult(rs)
spectrumID<-dbGetQuery(conn,getSpecID,basename(cdf.file))
rs<-dbSendStatement(conn,insertComment,note,'autoloader')
commentID<-dbGetQuery(conn,getCommentID,note)
rs<-dbSendStatement(conn,insertCommentRef,spectrumID$id,commentID$id)
```

## Scans

```{r insert.scans, eval=proceedFile}
df<-data.frame(spectrumID=1,scanid=1,mz=0.01,intensity=0.01)[FALSE,]
for(sp in spectra){
  md<-metaData(sp)
  rs<-dbSendStatement(conn,insertScan,
                      spectrumID$id,
                      md$number,
                      md$retentionTime,totalIonCurrent(sp))
}
#spectrumID<-dbGetQuery(conn,getSpecID,basename(cdf.file))
```

## Signal

Таблица *Signal* содержит сырые данные, как они получены из исходного файла.

### Disable referential constraints and indices
```
{r drop.reads.constraints}
rs<-dbSendStatement(conn,'alter table signal drop CONSTRAINT "signal_scanFK";')
    dbHasCompleted(rs)
    dbGetRowsAffected(rs)
    dbClearResult(rs)
rs<-dbSendStatement(conn,'drop INDEX "signal_mz";')
    dbHasCompleted(rs)
    dbGetRowsAffected(rs)
    dbClearResult(rs)
rs<-dbSendStatement(conn,'drop INDEX "signal_scan";')
    dbHasCompleted(rs)
    dbGetRowsAffected(rs)
    dbClearResult(rs)
```

```{r prepare.signal.file, eval=proceedFile}
sigFname<-normalizePath(paste0(dirname(knitr::current_input(dir = TRUE)),'/tmp_signal.tsv'))
system.time(res<-sapply(spectra,writeDTsignal,specID=spectrumID$id,fname=sigFname))
```

```{r load.signal.file, eval=proceedFile}
system(paste0('mclient  -d msinvent  -s  "COPY INTO ms.tmp_signal  FROM ',"'",sigFname,"'",';"'),intern = TRUE)->mcOut
mcOut
system2('wc', sigFname,stdout=TRUE)->wc
wc
wcn<-as.numeric(unlist(strsplit(trimws(wc),' ')))
wcn
system(paste0('gzip ',sigFname))
```

```{r populate.signal.table, eval=proceedFile}
before<-dbGetQuery(conn,'select count(*) as num from signal;')
before
rs<-dbSendStatement(conn,
                        paste('INSERT INTO signal(mz,scan,intensity)',
                              '(select mz,s.id as scan, intensity ',
                              'from tmp_signal t, scan s ',
                              'where s.spectrumid=t.spec and s.num=t.num);'))
after<-dbGetQuery(conn,'select count(*) as num from signal;')
after
if((after$num>before$num) & (after$num-before$num==wcn[1]) ){
  rs<-dbSendStatement(conn,'delete from tmp_signal;')
}
```


### Enable referential constraints
```
{r add.reads.constraints}
rs<-dbSendStatement(conn,'ALTER TABLE "ms"."signal" ADD CONSTRAINT "signal_scanFK" FOREIGN KEY ("scan") REFERENCES "ms"."scan" ("id");')
    dbHasCompleted(rs)
    dbGetRowsAffected(rs)
    dbClearResult(rs)
rs<-dbSendStatement(conn,'CREATE INDEX "signal_mz" ON "ms"."signal" ("mz");')
    dbHasCompleted(rs)
    dbGetRowsAffected(rs)
    dbClearResult(rs)
rs<-dbSendStatement(conn,'CREATE INDEX "signal_scan" ON "ms"."signal" ("scan");')
    dbHasCompleted(rs)
    dbGetRowsAffected(rs)
    dbClearResult(rs)

```
## Peaks

Таблица *Peaks* содержит выделенные из сырых данных пики, для улучшения качества данных все сканы выравниваются по отношению к скану с максимальным TIC, пики группируются с отностительной точностью 2e-5 и исключаются пики, встречающиеся менее чем в 25% сканов. 
```{r prepare.peaks, cache=TRUE, eval=proceedFile}
imTIC<-which.max(tic)
plot(spectra[[imTIC]])
origSpectra<-spectra
spectra <- calibrateIntensity(spectra, method="TIC")
calibrSpectra<-spectra
spectra <- alignSpectra(spectra,reference = spectra[[imTIC]],tolerance = 2e-4)
alSpectra<-spectra
peaks <- detectPeaks(spectra, SNR=1, halfWindowSize=halfWindowSize,
                       method="SuperSmoother")
peaks2 <- binPeaks(peaks,method = 'strict',tolerance = 2e-5)
fpeaks2 <- filterPeaks(peaks2, minFrequency=0.25)
featureMatrix2 <- intensityMatrix(fpeaks2, spectra)

```

### Disable referential constraints and indices
```
{r drop.peak.constraints}
rs<-dbSendStatement(conn,'alter table peak drop CONSTRAINT "peak_featureFK";')
    dbHasCompleted(rs)
    dbGetRowsAffected(rs)
    dbClearResult(rs)
rs<-dbSendStatement(conn,'alter table peak drop CONSTRAINT "peak_scanFK";')
    dbHasCompleted(rs)
    dbGetRowsAffected(rs)
    dbClearResult(rs)
rs<-dbSendStatement(conn,'drop INDEX "peak_mz";')
    dbHasCompleted(rs)
    dbGetRowsAffected(rs)
    dbClearResult(rs)
rs<-dbSendStatement(conn,'drop INDEX "peak_scan";')
    dbHasCompleted(rs)
    dbGetRowsAffected(rs)
    dbClearResult(rs)
```
```{r prepare.peak.file, eval=proceedFile}
peakFname<-normalizePath(paste0(dirname(knitr::current_input(dir = TRUE)),'/tmp_peak.tsv'))
system.time(res<-sapply(fpeaks2,writeDTpeak,specID=spectrumID$id,tic=tic,fname=peakFname))
```

```{r load.peak.file, eval=proceedFile}
system(paste0('mclient  -d msinvent  -s  "COPY INTO ms.tmp_peak  FROM ',"'",peakFname,"'",';"'),intern = TRUE)->mcOut
mcOut
system2('wc', peakFname,stdout=TRUE)->wc
wc
wcn<-as.numeric(unlist(strsplit(trimws(wc),' ')))
wcn
system(paste0('gzip ',peakFname))
```

```{r populate.peak.table, eval=proceedFile}
before<-dbGetQuery(conn,'select count(*) as num from peak;')
before
rs<-dbSendStatement(conn,
                        paste('INSERT INTO peak(mz,scan,intensity,norm2tic,sqrtnorm2tic,sqrtintensity,snr)',
                              '(select mz,s.id as scan, intensity, norm2tic, SQRT(norm2tic) as sqrtnorm2tic,',
                              ' SQRT(intensity) as sqrtintensity, snr',
                              'from tmp_peak t, scan s ',
                              'where s.spectrumid=t.spec and s.num=t.num);'))
after<-dbGetQuery(conn,'select count(*) as num from peak;')
after
if((after$num>before$num) & (after$num-before$num==wcn[1]) ){
  rs<-dbSendStatement(conn,'delete from tmp_peak;')
}
```

### Enable referential constraints
```
{r add.peak.constraints}
rs<-dbSendStatement(conn,'ALTER TABLE "ms"."peak" ADD CONSTRAINT "peak_featureFK" FOREIGN KEY ("feature") REFERENCES "ms"."features" ("id");')
    dbHasCompleted(rs)
    dbGetRowsAffected(rs)
    dbClearResult(rs)
rs<-dbSendStatement(conn,'ALTER TABLE "ms"."peak" ADD CONSTRAINT "peak_scanFK" FOREIGN KEY ("scan") REFERENCES "ms"."scan" ("id");')
    dbHasCompleted(rs)
    dbGetRowsAffected(rs)
    dbClearResult(rs)
rs<-dbSendStatement(conn,'CREATE INDEX "peak_mz" ON "ms"."peak" ("mz");')
    dbHasCompleted(rs)
    dbGetRowsAffected(rs)
    dbClearResult(rs)
rs<-dbSendStatement(conn,'CREATE INDEX "peak_scan" ON "ms"."peak" ("scan");')
    dbHasCompleted(rs)
    dbGetRowsAffected(rs)
    dbClearResult(rs)

```

## Features

# Appendix {.tabset}
## Functions
```{r functions, eval=FALSE, include=TRUE}
```

## Setup R
```{r setup, eval=FALSE}
```

## Versions
### Document version
```{r docVersion, echo=FALSE, results='asis', cache=FALSE}
cat(params$version)
```

### Session Info
```{r sessionInfo, echo=FALSE, results='asis', class='text', warning=FALSE}
pander(devtools::session_info())
```

